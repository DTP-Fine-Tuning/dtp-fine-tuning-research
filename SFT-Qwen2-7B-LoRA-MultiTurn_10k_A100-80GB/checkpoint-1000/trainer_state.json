{
  "best_global_step": 1000,
  "best_metric": 0.05926984176039696,
  "best_model_checkpoint": "./SFT-Qwen2-7B-LoRA-MultiTurn_10k_A100-80GB/checkpoint-1000",
  "epoch": 1.631321370309951,
  "eval_steps": 500,
  "global_step": 1000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "entropy": 0.4627087174355984,
      "epoch": 0.08156606851549755,
      "grad_norm": 0.20164573192596436,
      "learning_rate": 0.00015978260869565217,
      "loss": 0.4427,
      "mean_token_accuracy": 0.9012738192081451,
      "num_tokens": 1638400.0,
      "step": 50
    },
    {
      "entropy": 0.08811073988676071,
      "epoch": 0.1631321370309951,
      "grad_norm": 0.0917971134185791,
      "learning_rate": 0.0002999881159206177,
      "loss": 0.0863,
      "mean_token_accuracy": 0.9695737648010254,
      "num_tokens": 3276800.0,
      "step": 100
    },
    {
      "entropy": 0.076300940066576,
      "epoch": 0.24469820554649266,
      "grad_norm": 0.05574551224708557,
      "learning_rate": 0.0002992126920641052,
      "loss": 0.0754,
      "mean_token_accuracy": 0.9715834152698517,
      "num_tokens": 4915200.0,
      "step": 150
    },
    {
      "entropy": 0.07078814044594765,
      "epoch": 0.3262642740619902,
      "grad_norm": 0.05660427361726761,
      "learning_rate": 0.0002972317685206397,
      "loss": 0.0701,
      "mean_token_accuracy": 0.9723265743255616,
      "num_tokens": 6553600.0,
      "step": 200
    },
    {
      "entropy": 0.06910952389240264,
      "epoch": 0.4078303425774878,
      "grad_norm": 0.05189554765820503,
      "learning_rate": 0.00029406134930890415,
      "loss": 0.0682,
      "mean_token_accuracy": 0.9726844155788421,
      "num_tokens": 8192000.0,
      "step": 250
    },
    {
      "entropy": 0.06630128622055054,
      "epoch": 0.4893964110929853,
      "grad_norm": 0.05040724202990532,
      "learning_rate": 0.0002897270484655759,
      "loss": 0.0657,
      "mean_token_accuracy": 0.9730483615398406,
      "num_tokens": 9830400.0,
      "step": 300
    },
    {
      "entropy": 0.06618047825992107,
      "epoch": 0.5709624796084829,
      "grad_norm": 0.05092461034655571,
      "learning_rate": 0.000284263883107748,
      "loss": 0.0656,
      "mean_token_accuracy": 0.9729073059558868,
      "num_tokens": 11468800.0,
      "step": 350
    },
    {
      "entropy": 0.06446751184761525,
      "epoch": 0.6525285481239804,
      "grad_norm": 0.04111852869391441,
      "learning_rate": 0.00027771599052721206,
      "loss": 0.0638,
      "mean_token_accuracy": 0.9731918632984161,
      "num_tokens": 13107200.0,
      "step": 400
    },
    {
      "entropy": 0.06418288335204124,
      "epoch": 0.734094616639478,
      "grad_norm": 0.05751204863190651,
      "learning_rate": 0.0002701362716022168,
      "loss": 0.0636,
      "mean_token_accuracy": 0.9731766021251679,
      "num_tokens": 14745600.0,
      "step": 450
    },
    {
      "entropy": 0.06369987629354,
      "epoch": 0.8156606851549756,
      "grad_norm": 0.041845183819532394,
      "learning_rate": 0.00026158596340760396,
      "loss": 0.0632,
      "mean_token_accuracy": 0.9734025406837463,
      "num_tokens": 16384000.0,
      "step": 500
    },
    {
      "epoch": 0.8156606851549756,
      "eval_entropy": 0.06279883676996598,
      "eval_loss": 0.06217789649963379,
      "eval_mean_token_accuracy": 0.9738125205039978,
      "eval_num_tokens": 16384000.0,
      "eval_runtime": 48.0826,
      "eval_samples_per_second": 4.16,
      "eval_steps_per_second": 0.27,
      "step": 500
    },
    {
      "entropy": 0.06286070384085178,
      "epoch": 0.8972267536704731,
      "grad_norm": 0.03933974355459213,
      "learning_rate": 0.000252134144476234,
      "loss": 0.0624,
      "mean_token_accuracy": 0.973527718782425,
      "num_tokens": 18022400.0,
      "step": 550
    },
    {
      "entropy": 0.06199820563197136,
      "epoch": 0.9787928221859706,
      "grad_norm": 0.03591134026646614,
      "learning_rate": 0.00024185717670872876,
      "loss": 0.0615,
      "mean_token_accuracy": 0.973594286441803,
      "num_tokens": 19660800.0,
      "step": 600
    },
    {
      "entropy": 0.06157457433640957,
      "epoch": 1.0603588907014683,
      "grad_norm": 0.037991564720869064,
      "learning_rate": 0.0002308380884403804,
      "loss": 0.0612,
      "mean_token_accuracy": 0.9737707579135895,
      "num_tokens": 21282816.0,
      "step": 650
    },
    {
      "entropy": 0.06095530278980732,
      "epoch": 1.1419249592169658,
      "grad_norm": 0.03398370370268822,
      "learning_rate": 0.0002191659036494729,
      "loss": 0.0605,
      "mean_token_accuracy": 0.9737603795528412,
      "num_tokens": 22921216.0,
      "step": 700
    },
    {
      "entropy": 0.06089895263314247,
      "epoch": 1.2234910277324633,
      "grad_norm": 0.036120083183050156,
      "learning_rate": 0.00020693492272638757,
      "loss": 0.0603,
      "mean_token_accuracy": 0.9737689304351806,
      "num_tokens": 24559616.0,
      "step": 750
    },
    {
      "entropy": 0.0600502372533083,
      "epoch": 1.3050570962479608,
      "grad_norm": 0.03678113594651222,
      "learning_rate": 0.00019424396061420963,
      "loss": 0.0597,
      "mean_token_accuracy": 0.9739796042442321,
      "num_tokens": 26198016.0,
      "step": 800
    },
    {
      "entropy": 0.06012918524444103,
      "epoch": 1.3866231647634584,
      "grad_norm": 0.056663572788238525,
      "learning_rate": 0.0001811955484759503,
      "loss": 0.0596,
      "mean_token_accuracy": 0.9739417409896851,
      "num_tokens": 27836416.0,
      "step": 850
    },
    {
      "entropy": 0.06024324409663677,
      "epoch": 1.468189233278956,
      "grad_norm": 0.033632125705480576,
      "learning_rate": 0.0001678951053381703,
      "loss": 0.0599,
      "mean_token_accuracy": 0.9737896931171417,
      "num_tokens": 29474816.0,
      "step": 900
    },
    {
      "entropy": 0.05921147421002388,
      "epoch": 1.5497553017944536,
      "grad_norm": 0.031120045110583305,
      "learning_rate": 0.00015445008640335367,
      "loss": 0.0587,
      "mean_token_accuracy": 0.9742397379875183,
      "num_tokens": 31113216.0,
      "step": 950
    },
    {
      "entropy": 0.059347065165638924,
      "epoch": 1.631321370309951,
      "grad_norm": 0.03382084146142006,
      "learning_rate": 0.00014096911491187473,
      "loss": 0.059,
      "mean_token_accuracy": 0.974034560918808,
      "num_tokens": 32751616.0,
      "step": 1000
    },
    {
      "epoch": 1.631321370309951,
      "eval_entropy": 0.059796849122414224,
      "eval_loss": 0.05926984176039696,
      "eval_mean_token_accuracy": 0.9741718585674579,
      "eval_num_tokens": 32751616.0,
      "eval_runtime": 48.1039,
      "eval_samples_per_second": 4.158,
      "eval_steps_per_second": 0.27,
      "step": 1000
    }
  ],
  "logging_steps": 50,
  "max_steps": 1839,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.3973783479603692e+18,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
