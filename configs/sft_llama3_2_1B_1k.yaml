# Training Configuration for Llama 3.2 SFT (QLoRA fp16)
# Project: dtp-fine-tuning-research

# Model Configuration
model:
  name: "meta-llama/Llama-3.2-1B"   # model base
  trust_remote_code: true
  use_cache: false                  # biasanya dimatikan saat training + gradient_checkpointing

# Tokenizer Configuration
tokenizer:
  padding_side: "right"
  truncation_side: "right"
  trust_remote_code: true
  use_fast: true

# Quantization Configuration (BitsAndBytes / QLoRA)
quantization:
  load_in_4bit: true                # QLoRA: base model di-load 4bit
  bnb_4bit_quant_type: "nf4"
  bnb_4bit_compute_dtype: "float16" # sesuai permintaan: fp16 compute
  bnb_4bit_use_double_quant: true

# LoRA Configuration
lora:
  r: 16                             # kapasitas adaptor (bisa jadi knob eksperimen)
  lora_alpha: 32
  lora_dropout: 0.05
  bias: "none"
  task_type: "CAUSAL_LM"
  target_modules:                   # standar untuk LLaMA
    - "q_proj"
    - "k_proj"
    - "v_proj"
    - "o_proj"
    - "gate_proj"
    - "up_proj"
    - "down_proj"

# Dataset Configuration
dataset:
  name: "dtp-fine-tuning/dtp-multiturn-interview-1k-combined"
  split: "train"
  test_size: 0.05                   # ~50 contoh dev dari 1000
  seed: 42
  text_field: "text"                # sesuaikan dengan field setelah templating
  max_length: 2048                  # context ideal untuk sesi interview 1k (QLoRA masih aman)

# Training Arguments
training:
  output_dir: "./runs/llama3.2-1B_dtp-multiturn-interview-1k_qlora-r16-ctx2048"

  # batch & memory
  per_device_train_batch_size: 4
  per_device_eval_batch_size: 4
  gradient_accumulation_steps: 4    # effective batch â‰ˆ 16 contoh/step (1 GPU)
  gradient_checkpointing: true

  # epochs & steps
  num_train_epochs: 3
  max_steps: -1                     # dihitung otomatis dari epoch

  # optimizer & scheduler
  learning_rate: 0.0002
  warmup_ratio: 0.03
  lr_scheduler_type: "cosine"
  optim: "paged_adamw_8bit"
  weight_decay: 0.01
  max_grad_norm: 1.0

  # precision (QLoRA + fp16)
  fp16: true
  bf16: false

  # logging, eval, saving
  logging_steps: 20
  eval_strategy: "steps"
  eval_steps: 100
  save_strategy: "steps"
  save_steps: 100
  save_total_limit: 3

  load_best_model_at_end: true
  metric_for_best_model: "eval_loss"
  greater_is_better: false

  seed: 42
  report_to:
    - "wandb"

  # lainnya
  packing: false                    # tetap false untuk chat kalau pipeline belum support packing
  remove_unused_columns: true

# Chat Template Configuration
chat_template:
  system_message: "Anda adalah interviewer dari platform talenta digital. Tugas Anda adalah menggali detail pendidikan, tugas akhir, sertifikasi/pelatihan, dan pengalaman kerja talenta lewat percakapan tanya jawab."
  use_llama_format: true            # gunakan format chat LLaMA 3.x

# Weights & Biases Configuration
wandb:
  entity: "DTP2"
  project: "SFT Interview Experiment"
  name: "llama3.2-1B_qlora-r16_ctx2048_dtp-interview-1k"

# Paths (relative to project root)
paths:
  final_model_dir: "./models/llama3.2-1B_dtp-multiturn-interview-1k_qlora-r16-ctx2048/final_model"
